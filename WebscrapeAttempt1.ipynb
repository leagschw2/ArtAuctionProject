{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selenium used to open and interact with a webpage\n",
    "# BeautifulSoup used to parse the HTML of the webpage (extracts data from the HTML)\n",
    "# Pandas used to store the data in a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('--headless=new')\n",
    "driver = webdriver.Chrome(options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_all_pages(artist_name):\n",
    "    \"\"\"Scrapes all auction entries for an artist, handling pagination dynamically.\"\"\"\n",
    "    \n",
    "    formatted_name = artist_name.lower().replace(\" \", \"-\")\n",
    "    url = f\"https://www.artsy.net/artist/{formatted_name}/auction-results\"\n",
    "\n",
    "    driver.get(url)\n",
    "    time.sleep(5)  # Wait for the first page to load\n",
    "\n",
    "    all_work = []  # Store all auction entries\n",
    "    page_count = 1  # Track the number of pages scraped\n",
    "\n",
    "    while True:\n",
    "        # Parse page with BeautifulSoup\n",
    "        soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "\n",
    "        # Find all auction entries on the current page\n",
    "        auction_entries = soup.find_all(\"a\", class_=\"RouterLink__RouterAwareLink-sc-c712443b-0 laGLjt\")\n",
    "        all_work.extend(auction_entries)\n",
    "\n",
    "        print(f\"Page {page_count}: Collected {len(auction_entries)} entries.\")\n",
    "\n",
    "        # \"Next\" button\n",
    "\n",
    "\n",
    "    return all_work  # Return all collected auction entries\n",
    "\n",
    "# Example: Scrape all auction results for an artist\n",
    "artist_name = \"Titian\"\n",
    "all_entries = scrape_all_pages(artist_name)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
